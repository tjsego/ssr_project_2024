{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulates what a modeler would do when following the proposed pipeline and specifies a number of significant figures. \n",
    "\n",
    "Different software tools output data with different significant figures, which can have important effects on \n",
    "quantifying similarity (especially when variables are nearly constant). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as ipw\n",
    "\n",
    "import sim_lib\n",
    "\n",
    "res_dir = os.path.join('results', 'workflow_sim_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_string_antimony = \"\"\"\n",
    "species S, I, R, V;\n",
    "\n",
    "S -> I ; beta * S * V;\n",
    "I -> R ; delta * I;\n",
    "-> V  ; p * I - k * V;\n",
    "\n",
    "S = 1E6;\n",
    "I = 0.0;\n",
    "R = 0.0;\n",
    "V = 2.0;\n",
    "\n",
    "beta = 2.0E-6;\n",
    "k = 4.0;\n",
    "delta = 1E0;\n",
    "p = 25.0;\n",
    "\"\"\"\n",
    "var_names = ['S', 'I', 'R', 'V']\n",
    "err_thresh = 0.075\n",
    "stochastic = False\n",
    "t_fin = 10.0\n",
    "num_steps = 101\n",
    "num_samples_incr = 100\n",
    "param_dist = {'beta': ('norm', (2.0E-6, 0.2E-6))}\n",
    "sig_figs = 6  # For comparing to COPASI default data output\n",
    "\n",
    "model_string_sbml = sim_lib.antimony_to_sbml(model_string_antimony)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions for collecting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_arrs(_arr: np.ndarray, _num_extend: int):\n",
    "    if _num_extend <= 0:\n",
    "        raise ValueError\n",
    "\n",
    "    result = np.zeros((_arr.shape[0] + _num_extend, _arr.shape[1]), dtype=float)\n",
    "    result[:_arr.shape[0], :] = _arr\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_rr_time(_res):\n",
    "    return _res[:, _res.colnames.index('time')]\n",
    "\n",
    "\n",
    "def extract_rr_results(_res, _var_name: str):\n",
    "    return _res[:, _res.colnames.index(f'[{_var_name}]')]\n",
    "\n",
    "\n",
    "sim_lib.start_pool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ipw.Output()\n",
    "display(out)\n",
    "subout = ipw.Output()\n",
    "display(subout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime: ~13 minutes (M1 max, can vary a lot)\n",
    "\n",
    "sampling_err_thresh = 0.001\n",
    "sample_times = np.array([t_fin / num_steps * i for i in range(0, num_steps + 1)], dtype=float)\n",
    "\n",
    "num_times = len(sample_times)\n",
    "results = {name: np.zeros((num_samples_incr, num_steps), dtype=float) for name in var_names}\n",
    "\n",
    "stat_hist = []\n",
    "err_hist = []\n",
    "iter_current = 0\n",
    "err_current = min(1, err_thresh + 1)\n",
    "ecf_eval_info = []\n",
    "ks_stats_samp = []\n",
    "idx_current = 0\n",
    "rr = sim_lib.make_rr(model_string_sbml, stochastic)\n",
    "\n",
    "results_times = extract_rr_time(sim_lib.exec_rr(rr, t_fin, num_steps, stochastic))\n",
    "rr.resetAll()\n",
    "\n",
    "while err_current >= err_thresh:\n",
    "\n",
    "    with out:\n",
    "        clear_output()\n",
    "\n",
    "    if iter_current > 0:\n",
    "        out.append_stdout(f'Iteration {iter_current} ({idx_current}): {stat_hist[-1][1]}, {stat_hist[-1][2]} ({err_thresh})\\n')\n",
    "    else:\n",
    "        out.append_stdout(f'Iteration {iter_current} ({idx_current}): ({err_thresh})\\n')\n",
    "\n",
    "    num_samples_incr_curr = num_samples_incr\n",
    "\n",
    "    if iter_current > 2:\n",
    "        # Try to jump ahead\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "        for el in stat_hist:\n",
    "            x_data.append(el[0])\n",
    "            y_data.append(el[1] + 3 * el[2])\n",
    "        fit_num_samples = int(sim_lib.recommend(x_data, y_data, err_thresh))\n",
    "        fit_num_samples += fit_num_samples % 2\n",
    "        if fit_num_samples < idx_current:\n",
    "            num_samples_incr_curr = num_samples_incr\n",
    "        else:\n",
    "            num_samples_incr_curr = fit_num_samples - idx_current\n",
    "            out.append_stdout(f'Recommended sample size: {num_samples_incr_curr}\\n')\n",
    "            \n",
    "            # Limit, in case we get something crazy from a poor fit\n",
    "            num_samples_incr_curr = max(min(num_samples_incr_curr, 5000), num_samples_incr)\n",
    "            \n",
    "            out.append_stdout(f'Jumping ahead with fitted sample size increment: {num_samples_incr_curr}\\n')\n",
    "\n",
    "    if iter_current > 0:\n",
    "        # Extend data storage\n",
    "        for name in var_names:\n",
    "            results[name] = extend_arrs(results[name], num_samples_incr_curr)\n",
    "\n",
    "    out.append_stdout(f'Working {num_samples_incr_curr} jobs\\n')\n",
    "    idx_received = 0\n",
    "    for res in sim_lib.exec_rr_batch(num_samples_incr_curr, rr, t_fin, num_steps, stochastic, dists=param_dist, out=subout):\n",
    "        for name in var_names:\n",
    "            results[name][idx_current+idx_received, :] = sim_lib.round_arr_to_sigfigs(extract_rr_results(res, name), sig_figs)\n",
    "        idx_received += 1\n",
    "    with subout:\n",
    "        clear_output()\n",
    "    if idx_received != num_samples_incr_curr:\n",
    "        out.append_stderr(f'Received {idx_received} results, though {num_samples_incr_curr} were requested.\\n')\n",
    "    else:\n",
    "        out.append_stdout('All results received.\\n')\n",
    "    idx_current += idx_received\n",
    "    \n",
    "    out.append_stdout('Testing sampling\\n')\n",
    "\n",
    "    ks_stats_samp = sim_lib.test_sampling(results, err_thresh=sampling_err_thresh, out=subout)[0]\n",
    "    with subout:\n",
    "        clear_output()\n",
    "    stat_hist.append((idx_current, np.average(ks_stats_samp), np.std(ks_stats_samp)))\n",
    "    err_current = stat_hist[-1][1] + 3 * stat_hist[-1][2]\n",
    "    err_hist.append((iter_current, err_current))\n",
    "\n",
    "    out.append_stdout(f'Iteration {iter_current} ({idx_current}): {stat_hist[-1][1]}, {stat_hist[-1][2]} ({err_thresh})\\n')\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "    iter_current += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show distributions, for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, len(var_names), figsize=(10.0, 3.0), layout='compressed')\n",
    "for i, name in enumerate(var_names):\n",
    "    for j in range(int(results[name].shape[0]/2)):\n",
    "        axs[i].plot(results_times, results[name][j, :], alpha=0.01, color='gray')\n",
    "    axs[i].set_title(name)\n",
    "    axs[i].set_xlabel('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = int(idx_current/2)\n",
    "results_exp = {n: [results[n][:sample_size, i] for i in range(len(results_times))] for n in var_names}\n",
    "ecf_evals, _, ecf_eval_info = sim_lib.find_ecfs({n: results[n][:sample_size, :] for n in var_names})\n",
    "metadata = sim_lib.Metadata(sample_size=sample_size,\n",
    "                            simulator='deterministic',\n",
    "                            ks_stat_mean=np.mean(ks_stats_samp),\n",
    "                            ks_stat_stdev=np.std(ks_stats_samp),\n",
    "                            sample_times=results_times,\n",
    "                            ecf_evals=ecf_evals,\n",
    "                            ecf_eval_info=ecf_eval_info,\n",
    "                            param_dists=[sim_lib.ParamDist(param_name=n, dist_name=t[0], dist_params=t[1]) for n, t in param_dist.items()],\n",
    "                            sig_figs=sig_figs)\n",
    "print(metadata)\n",
    "\n",
    "if not os.path.isdir(res_dir):\n",
    "    os.makedirs(res_dir)\n",
    "\n",
    "fp = os.path.join(res_dir, 'sim_modeler.json')\n",
    "with open(fp, 'w') as f:\n",
    "    json.dump(metadata.to_json(), f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record data for later reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(res_dir, 'simdata_modeler.json'), 'w') as f:\n",
    "    json.dump(dict(sample_size=idx_current,\n",
    "                   sampling_err_thresh=sampling_err_thresh,\n",
    "                   results_times=results_times.tolist(),\n",
    "                   results={n: results[n].tolist() for n in var_names},\n",
    "                   ks_stats_samp=ks_stats_samp,\n",
    "                   err_hist=err_hist), \n",
    "              f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a sample, to verify\n",
    "idx_sample = 11\n",
    "eval_t_sample = {n: sim_lib.get_eval_info_times(*ecf_eval_info[n][idx_sample]) for n in var_names}\n",
    "ecfs_sample = {n: sim_lib.ecf(results_exp[n][idx_sample], eval_t_sample[n]) for n in var_names}\n",
    "\n",
    "fig, axs = plt.subplots(2, len(var_names), figsize=(10.0, 3.0), layout='compressed')\n",
    "for j, n in enumerate(var_names):\n",
    "    for i in range(2):\n",
    "        axs[i, j].plot(eval_t_sample[n], ecfs_sample[n][:, i])\n",
    "    \n",
    "    axs[0, j].set_title(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot distributions at a time of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_oi_idx = 2\n",
    "fig, ax = plt.subplots(len(var_names), 1, figsize=(10.0, 2.0 * len(var_names)), layout='compressed')\n",
    "\n",
    "for i, axi in enumerate(ax):\n",
    "    name = var_names[i]\n",
    "    axi.hist(results[name][:, res_oi_idx], density=True)\n",
    "    axi.set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show distribution of the final K-S statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# All of these distributions generate a reasonable fit\n",
    "\n",
    "# dist = stats.alpha\n",
    "# dist = stats.betaprime\n",
    "# dist = stats.exponnorm\n",
    "# dist = stats.f\n",
    "# dist = stats.fisk\n",
    "# dist = stats.gamma\n",
    "# dist = stats.genextreme\n",
    "# dist = stats.genlogistic\n",
    "# dist = stats.gennorm\n",
    "# dist = stats.gumbel_r\n",
    "# dist = stats.invgamma\n",
    "# dist = stats.invgauss\n",
    "# dist = stats.johnsonsb\n",
    "# dist = stats.johnsonsu\n",
    "# dist = stats.kstwobign\n",
    "dist = stats.lognorm\n",
    "# dist = stats.moyal\n",
    "# dist = stats.norm\n",
    "# dist = stats.norminvgauss\n",
    "# dist = stats.pearson3\n",
    "# dist = stats.recipinvgauss\n",
    "# dist = stats.skewnorm\n",
    "# dist = stats.weibull_max\n",
    "\n",
    "plt.hist(ks_stats_samp, alpha=0.5, label='data', density=True)\n",
    "\n",
    "fit = dist.fit(ks_stats_samp)\n",
    "print(fit)\n",
    "print(dist.stats(*fit))\n",
    "print(np.average(ks_stats_samp), np.std(ks_stats_samp))\n",
    "\n",
    "p = dist(*fit)\n",
    "xmin = min(ks_stats_samp) * 0.9\n",
    "xmax = max(ks_stats_samp) * 1.1\n",
    "x = np.arange(xmin, xmax, (xmax - xmin)/1000)\n",
    "plt.plot(x, p.pdf(x), 'k-', label='Fit: ' + dist.name)\n",
    "_ = plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stoch_repro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
